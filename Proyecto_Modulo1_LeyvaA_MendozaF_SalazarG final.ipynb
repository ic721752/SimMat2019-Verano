{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización mano de obra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## integrantes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Integrante 1: Angel Leyva Trejo\n",
    "+ Integrante 2: Felipe Neri Mendoza González\n",
    "+ Integrante 3: Gabriel Salazar Rámirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definimos variables**\n",
    "- $x_1$: número de maestros contratados en año i\n",
    "- $x_2$: número de albañiles contratados en año i\n",
    "- $x_3$: número de chalanes contratados en año i\n",
    "- $x_4$: número de maestros reclutados en año i\n",
    "- $x_5$: número de albañiles reclutados en año i\n",
    "- $x_6$: número de chalanes reclutados en año i\n",
    "- $x_7$: número de chalanes entrenados para albañiles en año i\n",
    "- $x_8$: número de albañiles entrenados para maestros en año i\n",
    "- $x_9$: número de maestros que descendieron a albañiles en año i\n",
    "- $x_10$: número de maestros que descendieron a chalanes en año i\n",
    "- $x_11$: número de albañiles que descendieron a chalanes en año i\n",
    "- $x_12$: número de maestros redundantes en año i\n",
    "- $x_13$: número de albañiles redundantes en año i\n",
    "- $x_14$: número de chalanes redundantes en año i\n",
    "- $x_15$: número de maestros que renunciaron en año i\n",
    "- $x_16$: número de albañiles que renunciaron en año i\n",
    "- $x_17$: número de chalanes que renunciaron en año i\n",
    "- $x_18$: número de maestros de sobra en año i\n",
    "- $x_19$: número de albañiles de sobra en año i\n",
    "- $x_110$: número de chalanes de sobra en año i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definir funciones de restricción**\n",
    " + $x_1$= (0.95$x_1$+0.90$x_4$+0.95$x_8$-$x_9$-$x_1 0$-$x_1 2$)\n",
    " + $x_2$= (0.95$x_2$+0.80$x_5$+0.95$x_7$-$x_8$-0.50$x_9$-$x_1 1$-$x_1 3$)\n",
    " + $x_3$= (0.90$x_3$+0.75$x_7$-$x_1 0$+0.50$x_1 1$-$x_1 4$)\n",
    " + $x_8$-0.25$x_1$<=0\n",
    " + $x_1 8$+$x_1 9$+$x_1 10$<=150\n",
    " + $x_1$-$-x_1 8$-0.5$x_1 5$=1000\n",
    " + $x_2$-$x_1 9$-0.5$x_1 6$=1400\n",
    " + $x_3$-$x_1 10$-0.5$x_1 7$=1000\n",
    " + $x_4$<=500\n",
    " + $x_5$<=800\n",
    " + $x_6$<=500\n",
    " + $x_1 5$<=50\n",
    " + $x_1 6$<=50\n",
    " + $x_1 7$<=50\n",
    " + $x_5$<=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definir función para minimizar redundancia**\n",
    "+ $x_1 2$+$x_1 3$+$x_1 4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definir función para minimizar costo**\n",
    "+ 400$x_7$+500$x_8$+200$x_1 4$+500$x_1 3$+500$x_1 2$+500$x_1 7$+400$x_1 6$+1500$x_1 10$+2000$x_1 9$+3000$x_1 8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     con: array([], dtype=float64)\n",
       "     fun: 540000.0\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 7\n",
       "   slack: array([575., 900.,   0.,   0.,   0.])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([   0.,    0.,    0.,    0.,    0.,    0.,  100., 1000.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.array(([1,1,0,0,0,0,0,0,0,0,0],[0,0,1,1,1,0,0,0,0,0,0],[0,0,0,0,0,0,0,-1,-1,0,0],[0,0,0,0,0,0,-1,0,0,-1,0],[0,0,0,0,0,-1,0,0,0,0,-1]))\n",
    "\n",
    "c=np.array(([400,500,500,500,200,400,400,500,3000,2000,1500])) \n",
    "b=(([575,900,-1000,-100,0]))\n",
    "        \n",
    "resultado=opt.linprog(c,A_ub=A,b_ub=b,)\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function linprog in module scipy.optimize._linprog:\n",
      "\n",
      "linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None, method='simplex', callback=None, options=None)\n",
      "    Minimize a linear objective function subject to linear\n",
      "    equality and inequality constraints. Linear Programming is intended to\n",
      "    solve the following problem form:\n",
      "    \n",
      "    Minimize::\n",
      "    \n",
      "        c @ x\n",
      "    \n",
      "    Subject to::\n",
      "    \n",
      "        A_ub @ x <= b_ub\n",
      "        A_eq @ x == b_eq\n",
      "         lb <= x <= ub\n",
      "    \n",
      "    where ``lb = 0`` and ``ub = None`` unless set in ``bounds``.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    c : 1D array\n",
      "        Coefficients of the linear objective function to be minimized.\n",
      "    A_ub : 2D array, optional\n",
      "        2D array such that ``A_ub @ x`` gives the values of the upper-bound\n",
      "        inequality constraints at ``x``.\n",
      "    b_ub : 1D array, optional\n",
      "        1D array of values representing the upper-bound of each inequality\n",
      "        constraint (row) in ``A_ub``.\n",
      "    A_eq : 2D, optional\n",
      "        2D array such that ``A_eq @ x`` gives the values of the equality\n",
      "        constraints at ``x``.\n",
      "    b_eq : 1D array, optional\n",
      "        1D array of values representing the RHS of each equality constraint\n",
      "        (row) in ``A_eq``.\n",
      "    bounds : sequence, optional\n",
      "        ``(min, max)`` pairs for each element in ``x``, defining\n",
      "        the bounds on that parameter. Use None for one of ``min`` or\n",
      "        ``max`` when there is no bound in that direction. By default\n",
      "        bounds are ``(0, None)`` (non-negative).\n",
      "        If a sequence containing a single tuple is provided, then ``min`` and\n",
      "        ``max`` will be applied to all variables in the problem.\n",
      "    method : str, optional\n",
      "        Type of solver.  :ref:`'simplex' <optimize.linprog-simplex>`\n",
      "        and :ref:`'interior-point' <optimize.linprog-interior-point>`\n",
      "        are supported.\n",
      "    callback : callable, optional (simplex only)\n",
      "        If a callback function is provided, it will be called within each\n",
      "        iteration of the simplex algorithm. The callback must require a\n",
      "        `scipy.optimize.OptimizeResult` consisting of the following fields:\n",
      "    \n",
      "            x : 1D array\n",
      "                The independent variable vector which optimizes the linear\n",
      "                programming problem.\n",
      "            fun : float\n",
      "                Value of the objective function.\n",
      "            success : bool\n",
      "                True if the algorithm succeeded in finding an optimal solution.\n",
      "            slack : 1D array\n",
      "                The values of the slack variables. Each slack variable\n",
      "                corresponds to an inequality constraint. If the slack is zero,\n",
      "                the corresponding constraint is active.\n",
      "            con : 1D array\n",
      "                The (nominally zero) residuals of the equality constraints\n",
      "                that is, ``b - A_eq @ x``\n",
      "            phase : int\n",
      "                The phase of the optimization being executed. In phase 1 a basic\n",
      "                feasible solution is sought and the T has an additional row\n",
      "                representing an alternate objective function.\n",
      "            status : int\n",
      "                An integer representing the exit status of the optimization::\n",
      "    \n",
      "                     0 : Optimization terminated successfully\n",
      "                     1 : Iteration limit reached\n",
      "                     2 : Problem appears to be infeasible\n",
      "                     3 : Problem appears to be unbounded\n",
      "                     4 : Serious numerical difficulties encountered\n",
      "    \n",
      "            nit : int\n",
      "                The number of iterations performed.\n",
      "            message : str\n",
      "                A string descriptor of the exit status of the optimization.\n",
      "    \n",
      "    options : dict, optional\n",
      "        A dictionary of solver options. All methods accept the following\n",
      "        generic options:\n",
      "    \n",
      "            maxiter : int\n",
      "                Maximum number of iterations to perform.\n",
      "            disp : bool\n",
      "                Set to True to print convergence messages.\n",
      "    \n",
      "        For method-specific options, see :func:`show_options('linprog')`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : OptimizeResult\n",
      "        A :class:`scipy.optimize.OptimizeResult` consisting of the fields:\n",
      "    \n",
      "            x : 1D array\n",
      "                The independent variable vector which optimizes the linear\n",
      "                programming problem.\n",
      "            fun : float\n",
      "                Value of the objective function.\n",
      "            slack : 1D array\n",
      "                The values of the slack variables. Each slack variable\n",
      "                corresponds to an inequality constraint. If the slack is zero,\n",
      "                then the corresponding constraint is active.\n",
      "            con : 1D array\n",
      "                The (nominally zero) residuals of the equality constraints,\n",
      "                that is, ``b - A_eq @ x``\n",
      "            success : bool\n",
      "                Returns True if the algorithm succeeded in finding an optimal\n",
      "                solution.\n",
      "            status : int\n",
      "                An integer representing the exit status of the optimization::\n",
      "    \n",
      "                     0 : Optimization terminated successfully\n",
      "                     1 : Iteration limit reached\n",
      "                     2 : Problem appears to be infeasible\n",
      "                     3 : Problem appears to be unbounded\n",
      "                     4 : Serious numerical difficulties encountered\n",
      "    \n",
      "            nit : int\n",
      "                The number of iterations performed.\n",
      "            message : str\n",
      "                A string descriptor of the exit status of the optimization.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    show_options : Additional options accepted by the solvers\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This section describes the available solvers that can be selected by the\n",
      "    'method' parameter. The default method\n",
      "    is :ref:`Simplex <optimize.linprog-simplex>`.\n",
      "    :ref:`Interior point <optimize.linprog-interior-point>` is also available.\n",
      "    \n",
      "    Method *simplex* uses the simplex algorithm (as it relates to linear\n",
      "    programming, NOT the Nelder-Mead simplex) [1]_, [2]_. This algorithm\n",
      "    should be reasonably reliable and fast for small problems.\n",
      "    \n",
      "    .. versionadded:: 0.15.0\n",
      "    \n",
      "    Method *interior-point* uses the primal-dual path following algorithm\n",
      "    as outlined in [4]_. This algorithm is intended to provide a faster\n",
      "    and more reliable alternative to *simplex*, especially for large,\n",
      "    sparse problems. Note, however, that the solution returned may be slightly\n",
      "    less accurate than that of the simplex method and may not correspond with a\n",
      "    vertex of the polytope defined by the constraints.\n",
      "    \n",
      "    Before applying either method a presolve procedure based on [8]_ attempts to\n",
      "    identify trivial infeasibilities, trivial unboundedness, and potential\n",
      "    problem simplifications. Specifically, it checks for:\n",
      "    \n",
      "    - rows of zeros in ``A_eq`` or ``A_ub``, representing trivial constraints;\n",
      "    - columns of zeros in ``A_eq`` `and` ``A_ub``, representing unconstrained\n",
      "      variables;\n",
      "    - column singletons in ``A_eq``, representing fixed variables; and\n",
      "    - column singletons in ``A_ub``, representing simple bounds.\n",
      "    \n",
      "    If presolve reveals that the problem is unbounded (e.g. an unconstrained\n",
      "    and unbounded variable has negative cost) or infeasible (e.g. a row of\n",
      "    zeros in ``A_eq`` corresponds with a nonzero in ``b_eq``), the solver\n",
      "    terminates with the appropriate status code. Note that presolve terminates\n",
      "    as soon as any sign of unboundedness is detected; consequently, a problem\n",
      "    may be reported as unbounded when in reality the problem is infeasible\n",
      "    (but infeasibility has not been detected yet). Therefore, if the output\n",
      "    message states that unboundedness is detected in presolve and it is\n",
      "    necessary to know whether the problem is actually infeasible, set option\n",
      "    ``presolve=False``.\n",
      "    \n",
      "    If neither infeasibility nor unboundedness are detected in a single pass\n",
      "    of the presolve check, bounds are tightened where possible and fixed\n",
      "    variables are removed from the problem. Then, linearly dependent rows\n",
      "    of the ``A_eq`` matrix are removed, (unless they represent an\n",
      "    infeasibility) to avoid numerical difficulties in the primary solve\n",
      "    routine. Note that rows that are nearly linearly dependent (within a\n",
      "    prescribed tolerance) may also be removed, which can change the optimal\n",
      "    solution in rare cases. If this is a concern, eliminate redundancy from\n",
      "    your problem formulation and run with option ``rr=False`` or\n",
      "    ``presolve=False``.\n",
      "    \n",
      "    Several potential improvements can be made here: additional presolve\n",
      "    checks outlined in [8]_ should be implemented, the presolve routine should\n",
      "    be run multiple times (until no further simplifications can be made), and\n",
      "    more of the efficiency improvements from [5]_ should be implemented in the\n",
      "    redundancy removal routines.\n",
      "    \n",
      "    After presolve, the problem is transformed to standard form by converting\n",
      "    the (tightened) simple bounds to upper bound constraints, introducing\n",
      "    non-negative slack variables for inequality constraints, and expressing\n",
      "    unbounded variables as the difference between two non-negative variables.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Dantzig, George B., Linear programming and extensions. Rand\n",
      "           Corporation Research Study Princeton Univ. Press, Princeton, NJ,\n",
      "           1963\n",
      "    .. [2] Hillier, S.H. and Lieberman, G.J. (1995), \"Introduction to\n",
      "           Mathematical Programming\", McGraw-Hill, Chapter 4.\n",
      "    .. [3] Bland, Robert G. New finite pivoting rules for the simplex method.\n",
      "           Mathematics of Operations Research (2), 1977: pp. 103-107.\n",
      "    .. [4] Andersen, Erling D., and Knud D. Andersen. \"The MOSEK interior point\n",
      "           optimizer for linear programming: an implementation of the\n",
      "           homogeneous algorithm.\" High performance optimization. Springer US,\n",
      "           2000. 197-232.\n",
      "    .. [5] Andersen, Erling D. \"Finding all linearly dependent rows in\n",
      "           large-scale linear programming.\" Optimization Methods and Software\n",
      "           6.3 (1995): 219-227.\n",
      "    .. [6] Freund, Robert M. \"Primal-Dual Interior-Point Methods for Linear\n",
      "           Programming based on Newton's Method.\" Unpublished Course Notes,\n",
      "           March 2004. Available 2/25/2017 at\n",
      "           https://ocw.mit.edu/courses/sloan-school-of-management/15-084j-nonlinear-programming-spring-2004/lecture-notes/lec14_int_pt_mthd.pdf\n",
      "    .. [7] Fourer, Robert. \"Solving Linear Programs by Interior-Point Methods.\"\n",
      "           Unpublished Course Notes, August 26, 2005. Available 2/25/2017 at\n",
      "           http://www.4er.org/CourseNotes/Book%20B/B-III.pdf\n",
      "    .. [8] Andersen, Erling D., and Knud D. Andersen. \"Presolving in linear\n",
      "           programming.\" Mathematical Programming 71.2 (1995): 221-245.\n",
      "    .. [9] Bertsimas, Dimitris, and J. Tsitsiklis. \"Introduction to linear\n",
      "           programming.\" Athena Scientific 1 (1997): 997.\n",
      "    .. [10] Andersen, Erling D., et al. Implementation of interior point\n",
      "            methods for large scale linear programming. HEC/Universite de\n",
      "            Geneve, 1996.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Consider the following problem:\n",
      "    \n",
      "    Minimize::\n",
      "    \n",
      "        f = -1x[0] + 4x[1]\n",
      "    \n",
      "    Subject to::\n",
      "    \n",
      "        -3x[0] + 1x[1] <= 6\n",
      "         1x[0] + 2x[1] <= 4\n",
      "                  x[1] >= -3\n",
      "          -inf <= x[0] <= inf\n",
      "    \n",
      "    This problem deviates from the standard linear programming problem.\n",
      "    In standard form, linear programming problems assume the variables x are\n",
      "    non-negative. Since the problem variables don't have the standard bounds of\n",
      "    ``(0, None)``, the variable bounds must be set using ``bounds`` explicitly.\n",
      "    \n",
      "    There are two upper-bound constraints, which can be expressed as\n",
      "    \n",
      "    dot(A_ub, x) <= b_ub\n",
      "    \n",
      "    The input for this problem is as follows:\n",
      "    \n",
      "    >>> c = [-1, 4]\n",
      "    >>> A = [[-3, 1], [1, 2]]\n",
      "    >>> b = [6, 4]\n",
      "    >>> x0_bounds = (None, None)\n",
      "    >>> x1_bounds = (-3, None)\n",
      "    >>> from scipy.optimize import linprog\n",
      "    >>> res = linprog(c, A_ub=A, b_ub=b, bounds=(x0_bounds, x1_bounds),\n",
      "    ...               options={\"disp\": True})\n",
      "    Optimization terminated successfully.\n",
      "    Current function value: -22.000000\n",
      "    Iterations: 5 # may vary\n",
      "    >>> print(res)\n",
      "         con: array([], dtype=float64)\n",
      "         fun: -22.0\n",
      "     message: 'Optimization terminated successfully.'\n",
      "         nit: 5 # may vary\n",
      "       slack: array([39.,  0.]) # may vary\n",
      "      status: 0\n",
      "     success: True\n",
      "           x: array([10., -3.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(opt.linprog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
